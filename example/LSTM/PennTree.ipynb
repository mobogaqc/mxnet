{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM on PennTreeBank\n",
    "-----\n",
    "This is an example to show how to use MXNet low-level symbol to make a LSTM network.\n",
    "\n",
    "We would like to thank Wojciech Zaremba for his work LSTM in Torch. The data is same to Wojciech used in Torch LSTM. https://github.com/wojzaremba/lstm\n",
    "\n",
    "To get the data, please download directly from:\n",
    "\n",
    "Training text: https://raw.githubusercontent.com/wojzaremba/lstm/master/data/ptb.train.txt\n",
    "\n",
    "Validation text: https://raw.githubusercontent.com/wojzaremba/lstm/master/data/ptb.valid.txt\n",
    "\n",
    "Test text: https://raw.githubusercontent.com/wojzaremba/lstm/master/data/ptb.test.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import mxnet as mx\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "    Build LSTM Symbol\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    num_hidden: int\n",
    "        hidden unit in LSTM\n",
    "    x: symbol\n",
    "        input x\n",
    "    prev_c: symbol\n",
    "        previous cell\n",
    "    prev_h: symbol\n",
    "        previous hidden\n",
    "    layer_prefix: str\n",
    "        name prefix for layer\n",
    "    t_prefix: str\n",
    "        name prefix for time\n",
    "    arg_param: dict: str->symbol\n",
    "        arguments symbol for the lstm symbol\n",
    "    aux_param: dict: str->symbol\n",
    "        auxiliary states symbol for the lstm symbol\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    output: symbol\n",
    "        grouped lstm output [c, h]\n",
    "\n",
    "    arg_param: dict: str->symbol\n",
    "        arguments symbol of the lstm symbol\n",
    "\n",
    "    aux_param: dict: str->symbol\n",
    "        auxiliary states symbol of the lstm symbol\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lstm_symbol(num_hidden,\n",
    "                x, prev_c, prev_h,\n",
    "                layer_prefix, t_prefix,\n",
    "                arg_param=None, aux_param=None,\n",
    "                **kwargs):\n",
    "    # name and variable\n",
    "    i2h_name = \"%s_i2h\" % layer_prefix\n",
    "    h2h_name = \"%s_h2h\" % layer_prefix\n",
    "    exist_flag = True\n",
    "    if arg_param == None or i2h_name + \"_weight\" not in arg_param:\n",
    "        exist_flag = False\n",
    "\n",
    "    if not exist_flag:\n",
    "        if arg_param == None:\n",
    "            arg_param = {}\n",
    "        arg_param[i2h_name + \"_weight\"] = mx.sym.Variable(i2h_name + \"_weight\")\n",
    "        arg_param[i2h_name + \"_bias\"] = mx.sym.Variable(i2h_name + \"_bias\")\n",
    "        arg_param[h2h_name + \"_weight\"] = mx.sym.Variable(h2h_name + \"_weight\")\n",
    "        arg_param[h2h_name + \"_bias\"] = mx.sym.Variable(h2h_name + \"_bias\")\n",
    "    if not exist_flag:\n",
    "        if aux_param == None:\n",
    "            aux_param = {}\n",
    "        aux_param[i2h_name + \"_moving_mean\"] = mx.sym.Variable(i2h_name + \"_moving_mean\")\n",
    "        aux_param[i2h_name + \"_moving_var\"] = mx.sym.Variable(i2h_name + \"_moving_var\")\n",
    "        aux_param[h2h_name + \"_moving_mean\"] = mx.sym.Variable(h2h_name + \"_moving_mean\")\n",
    "        aux_param[h2h_name + \"_moving_var\"] = mx.sym.Variable(h2h_name + \"_moving_var\")\n",
    "\n",
    "    # transform \n",
    "    i2h = mx.sym.FullyConnected(*[x,\n",
    "                                  arg_param[i2h_name + \"_weight\"],\n",
    "                                  arg_param[i2h_name + \"_bias\"]],\n",
    "                                  num_hidden=num_hidden * 4,\n",
    "                                  name=i2h_name)\n",
    "    h2h = mx.sym.FullyConnected(*[prev_h,\n",
    "                                  arg_param[h2h_name + \"_weight\"],\n",
    "                                  arg_param[h2h_name + \"_bias\"]],\n",
    "                                  num_hidden=num_hidden * 4,\n",
    "                                  name=h2h_name)\n",
    "    gates = i2h + h2h\n",
    "\n",
    "    # gates\n",
    "    slice_gates = mx.sym.SliceChannel(data=gates, num_outputs=4)\n",
    "    in_gate = mx.sym.Activation(data=slice_gates[0], act_type=\"sigmoid\")\n",
    "    in_transform = mx.sym.Activation(data=slice_gates[1], act_type=\"tanh\")\n",
    "    forget_gate = mx.sym.Activation(data=slice_gates[2], act_type=\"sigmoid\")\n",
    "    out_gate = mx.sym.Activation(data=slice_gates[3], act_type=\"sigmoid\")\n",
    "\n",
    "    # cal states\n",
    "    next_c = (forget_gate * prev_c) + (in_gate * in_transform)\n",
    "    next_h = out_gate * mx.sym.Activation(data=next_c, act_type=\"tanh\")\n",
    "    # We need to block gradient to set 0 gradient back automatically\n",
    "    next_c = mx.sym.BlockGrad(data=next_c, name=\"%s_%s_c\" % (t_prefix, layer_prefix))\n",
    "    next_h = mx.sym.BlockGrad(data=next_h, name=\"%s_%s_h\" % (t_prefix, layer_prefix))\n",
    "    # if you like you can add a dropout symbol here\n",
    "    # next_h = mx.sym.Dropout(data=next_h, p=0.5)\n",
    "    output = mx.symbol.Group([next_c, next_h])\n",
    "    return (output, arg_param, aux_param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "    Build a multi-layer LSTM model for a single component in unrolled RNN\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    num_layer: int\n",
    "        layers of LSTM network\n",
    "    num_hidden: int\n",
    "        hidden unit in each LSTM layer\n",
    "    num_embed: int\n",
    "        dimention of word embedding\n",
    "    num_label: int\n",
    "        output label dimention\n",
    "    prev_states: list of tuple (prev_c, prev_h)\n",
    "        prev_states for each LSTM layer\n",
    "    t_prefix: str\n",
    "        prefix name of time\n",
    "    embed_var: list of symbol\n",
    "        vairable for embedding layer\n",
    "    cls_var: list of symbol\n",
    "        variable for linear classifier\n",
    "    arg_param: dict: str->symbol\n",
    "        arguments symbol of the lstm symbol\n",
    "    aux_param: dict: str->symbol\n",
    "        auxiliary states symbol of the lstm symbol\n",
    "\n",
    "    Returns:\n",
    "    layers : list of symbol\n",
    "        layers of current component\n",
    "    arg_param: dict: str->symbol\n",
    "        arguments symbol of the lstm symbol\n",
    "\n",
    "    aux_param: dict: str->symbol\n",
    "        auxiliary states symbol of the lstm symbol\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_model(num_layer, num_hidden, num_embed, num_label,\n",
    "                 prev_states,\n",
    "                 t_prefix,\n",
    "                 embed_var, cls_var, arg_param=None, aux_param=None,\n",
    "                 **kwargs):\n",
    "    layers = []\n",
    "    data = mx.sym.Variable(\"%s_data\" % t_prefix)\n",
    "    embed_layer = mx.sym.FullyConnected(*[data, embed_var[0], embed_var[1]],\n",
    "                                        num_hidden=num_embed, name=\"embedding\")\n",
    "    for i in range(num_layer):\n",
    "        layer_prefix = \"layer_%d\" % i\n",
    "        prev_c, prev_h = prev_states[i]\n",
    "        if i == 0:\n",
    "            data = embed_layer\n",
    "        else:\n",
    "            data = layers[-1][1]\n",
    "        args = None\n",
    "        auxs = None\n",
    "        if arg_param != None:\n",
    "            args = arg_param\n",
    "        if aux_param != None:\n",
    "            auxs = aux_param\n",
    "        lstm, arg_param, aux_param = lstm_symbol(num_hidden,\n",
    "                                                 data, prev_c, prev_h,\n",
    "                                                 layer_prefix, t_prefix,\n",
    "                                                 args, auxs,\n",
    "                                                 **kwargs)\n",
    "        layers.append(lstm)\n",
    "    fc = mx.sym.FullyConnected(*[layers[-1][1], cls_var[0], cls_var[1]],\n",
    "                               num_hidden=num_label, name=\"cls\")\n",
    "    sm = mx.sym.Softmax(data=fc, name=\"%s\" % t_prefix)\n",
    "    layers.append(sm)\n",
    "    return layers, arg_param, aux_param"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "    Setup Recurrent Network Symbol\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    seq_len: int\n",
    "        length of sequence\n",
    "    num_layer: int\n",
    "        layer of hidden lstm layers\n",
    "    num_embed: int\n",
    "        dimention of embeeding layer\n",
    "    num_label: int\n",
    "        dimention of output space\n",
    "    models = []\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    rnn: symbol\n",
    "        A final symbol of RNN network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def setup_rnn_symbol(seq_len, num_layer, num_hidden, num_embed, num_label, **kwargs):\n",
    "    models = []\n",
    "    arg_param = None\n",
    "    aux_param = None\n",
    "    embed_var = [mx.sym.Variable(\"embed_weight\"), mx.sym.Variable(\"embed_bias\")]\n",
    "    cls_var = [mx.sym.Variable(\"cls_weight\"), mx.sym.Variable(\"cls_bias\")]\n",
    "    init_states = []\n",
    "\n",
    "    for i in range(num_layer):\n",
    "        init_c = mx.sym.Variable(\"init_c_%d\" % i)\n",
    "        init_h = mx.sym.Variable(\"init_h_%d\" % i)\n",
    "        init_states.append([init_c, init_h])\n",
    "\n",
    "    for i in range(seq_len):\n",
    "        t_prefix = \"t_%d\" % i\n",
    "        if i == 0:\n",
    "            states = init_states\n",
    "        else:\n",
    "            states = [(models[-1][j][0], models[-1][j][1]) for j in range(num_layer)]\n",
    "        model, arg_param, aux_param = create_model(num_layer, num_hidden, num_embed, num_label,\n",
    "                                                    states, t_prefix,\n",
    "                                                    embed_var, cls_var,\n",
    "                                                    arg_param, aux_param,\n",
    "                                                    **kwargs)\n",
    "        models.append(model)\n",
    "    prob = mx.sym.Group([md[-1] for md in models])\n",
    "    state = mx.sym.Group([models[-1][i] for i in range(num_layer)])\n",
    "    rnn = mx.sym.Group([prob, state])\n",
    "    return rnn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "    Setup Recurrent Network Executor\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    ctx: Context\n",
    "        running context\n",
    "    seq_len: int\n",
    "        length of sequence\n",
    "    num_layer: int\n",
    "        layer of hidden lstm layers\n",
    "    num_embed: int\n",
    "        dimention of embeeding layer\n",
    "    num_label: int\n",
    "        dimention of output space\n",
    "    batch_size: int\n",
    "        number of batch_size\n",
    "    Returns:\n",
    "    --------\n",
    "    rnn: executor\n",
    "        A final RNN network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def setup_rnn(ctx, seq_len, num_layer, num_hidden, num_embed, num_label, batch_size,\n",
    "              initializer=mx.init.Uniform(0.05)):\n",
    "\n",
    "    # get symbol\n",
    "    rnn_sym = setup_rnn_symbol(seq_len, num_layer, num_hidden, num_embed, num_label)\n",
    "    input_shapes = {}\n",
    "    for name in rnn_sym.list_arguments():\n",
    "        if \"init\" in name:\n",
    "            input_shapes[name] = (batch_size, num_hidden)\n",
    "        if \"data\" in name:\n",
    "            input_shapes[name] = (batch_size, num_label)\n",
    "    # bind symbol\n",
    "    rnn_model = rnn_sym.simple_bind(ctx=ctx, **input_shapes)\n",
    "    # init weight\n",
    "    names = rnn_sym.list_arguments()\n",
    "    args = dict(zip(names, rnn_model.arg_arrays))\n",
    "    grad = dict(zip(names, rnn_model.grad_arrays))\n",
    "    for name, arr in args.items():\n",
    "        if name.endswith(\"weight\") or name.endswith(\"bias\") or \\\n",
    "           name.endswith(\"gamma\") or name.endswith(\"beta\"):\n",
    "            initializer(name, arr)\n",
    "    # structure for later use\n",
    "    param_array = []\n",
    "    for i in range(len(names)):\n",
    "        name = names[i]\n",
    "        if name.endswith(\"weight\") or name.endswith(\"bias\") or \\\n",
    "           name.endswith(\"gamma\") or name.endswith(\"beta\"):\n",
    "            param_array.append((i, args[name], grad[name]))\n",
    "    \n",
    "    init_states = [(args[\"init_c_%d\" % i], args[\"init_h_%d\" % i]) for i in range(num_layer)]\n",
    "    last_states = [(rnn_model.outputs[seq_len + i * 2], rnn_model.outputs[seq_len + i *2 + 1]) for i in range(num_layer)]\n",
    "    return (rnn_sym, rnn_model, param_array, init_states, last_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Logloss(y, prob):\n",
    "    #eps = 1e-6\n",
    "    #return -np.sum(np.log(np.maximum(np.choose(y.astype(\"int32\"), prob.T), eps)))\n",
    "    loss = 0.0\n",
    "    for i in range(prob.shape[0]):\n",
    "        loss += -np.log(np.max(prob[i, y[i]], 1e-8))\n",
    "    loss /= prob.shape[0]\n",
    "    return loss\n",
    "\n",
    "def set_onehot_input(onehot, xidx):\n",
    "    onehot[:] = 0.\n",
    "    onehot[np.arange(onehot.shape[0]), xidx.astype(\"int32\")] = 1.\n",
    "\n",
    "def load_data(path, dic=None):\n",
    "    fi = open(path)\n",
    "    content = fi.read()\n",
    "    content = content.replace('\\n', '<eos>')\n",
    "    content = content.split(' ')\n",
    "    print(\"Loading %s, size of data = %d\" % (path, len(content)))\n",
    "    x = np.zeros(len(content))\n",
    "    if dic == None:\n",
    "        dic = {}\n",
    "    idx = 0\n",
    "    for i in range(len(content)):\n",
    "        word = content[i]\n",
    "        if len(word) == 0:\n",
    "            continue\n",
    "        if not word in dic:\n",
    "            dic[word] = idx\n",
    "            idx += 1\n",
    "        x[i] = dic[word]\n",
    "    print(\"Unique token: %d\" % len(dic))\n",
    "    return x, dic\n",
    "\n",
    "def replicate_data(x, batch_size):\n",
    "    nbatch = int(x.shape[0] / batch_size)\n",
    "    x_cut = x[:nbatch * batch_size]\n",
    "    data = x_cut.reshape((nbatch, batch_size), order='F')\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ./data/ptb.train.txt, size of data = 929590\n",
      "Unique token: 10000\n",
      "Loading ./data/ptb.valid.txt, size of data = 73761\n",
      "Unique token: 10000\n"
     ]
    }
   ],
   "source": [
    "batch_size = 20\n",
    "seq_len = 20\n",
    "vocab = 10000\n",
    "rnn_hidden = 200\n",
    "embed = 200\n",
    "num_layer = 2\n",
    "num_round = 4\n",
    "ctx = mx.cpu()\n",
    "optimizer = mx.optimizer.SGD(learning_rate=0.01, wd=0.0001)\n",
    "# rnn model\n",
    "rnn_sym, rnn, param_array, init_states, last_states,  = setup_rnn(ctx=ctx, \n",
    "                                                                  seq_len=seq_len, \n",
    "                                                                  num_layer=num_layer, \n",
    "                                                                  num_hidden=rnn_hidden, \n",
    "                                                                  num_embed=embed, \n",
    "                                                                  num_label=vocab, \n",
    "                                                                  batch_size=batch_size)\n",
    "seq_prob = [mx.nd.zeros(ctx=mx.cpu(), shape=rnn.outputs[i].shape) for i in range(seq_len)]\n",
    "param_dict = dict(zip(rnn_sym.list_arguments(), rnn.arg_arrays))\n",
    "# load data\n",
    "X_train, dic = load_data(\"./data/ptb.train.txt\")\n",
    "X_val, _ = load_data(\"./data/ptb.valid.txt\", dic)\n",
    "X_train_batch = replicate_data(X_train, batch_size)\n",
    "X_val_batch = replicate_data(X_val, batch_size)\n",
    "onehot = np.zeros((batch_size, vocab), dtype='float32')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0], Batch [20]: NLL=8.503, Prep=4931.846\n",
      "Epoch [0], Batch [40]: NLL=8.511, Prep=4971.079\n",
      "Epoch [0], Batch [60]: NLL=8.366, Prep=4300.328\n",
      "Epoch [0], Batch [80]: NLL=8.273, Prep=3917.564\n",
      "Epoch [0], Batch [100]: NLL=8.241, Prep=3793.372\n",
      "Epoch [0], Batch [120]: NLL=8.146, Prep=3448.532\n",
      "Epoch [0], Batch [140]: NLL=8.062, Prep=3172.689\n",
      "Epoch [0], Batch [160]: NLL=8.041, Prep=3105.142\n",
      "Epoch [0], Batch [180]: NLL=8.107, Prep=3318.143\n",
      "Epoch [0], Batch [200]: NLL=8.091, Prep=3264.713\n",
      "Epoch [0], Batch [220]: NLL=8.025, Prep=3055.690\n",
      "Epoch [0], Batch [240]: NLL=8.020, Prep=3040.329\n",
      "Epoch [0], Batch [260]: NLL=7.993, Prep=2960.196\n",
      "Epoch [0], Batch [280]: NLL=7.970, Prep=2892.389\n",
      "Epoch [0], Batch [300]: NLL=8.021, Prep=3042.987\n",
      "Epoch [0], Batch [320]: NLL=7.979, Prep=2918.540\n",
      "Epoch [0], Batch [340]: NLL=7.951, Prep=2839.064\n",
      "Epoch [0], Batch [360]: NLL=7.982, Prep=2927.875\n",
      "Epoch [0], Batch [380]: NLL=7.989, Prep=2948.181\n",
      "Epoch [0], Batch [400]: NLL=7.966, Prep=2880.162\n",
      "Epoch [0], Batch [420]: NLL=7.942, Prep=2813.045\n",
      "Epoch [0], Batch [440]: NLL=7.954, Prep=2847.630\n",
      "Epoch [0], Batch [460]: NLL=7.914, Prep=2735.021\n",
      "Epoch [0], Batch [480]: NLL=7.878, Prep=2637.867\n",
      "Epoch [0], Batch [500]: NLL=7.872, Prep=2624.014\n",
      "Epoch [0], Batch [520]: NLL=7.845, Prep=2552.158\n",
      "Epoch [0], Batch [540]: NLL=7.813, Prep=2472.874\n",
      "Epoch [0], Batch [560]: NLL=7.801, Prep=2443.447\n",
      "Epoch [0], Batch [580]: NLL=7.772, Prep=2372.508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.4/dist-packages/ipykernel/__main__.py:6: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/usr/local/lib/python3.4/dist-packages/ipykernel/__main__.py:7: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/usr/local/lib/python3.4/dist-packages/ipykernel/__main__.py:21: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-e75e396a22bc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[1;31m# train\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[1;32mwhile\u001b[0m \u001b[0mnbatch\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mX_train_batch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m         \u001b[0mset_rnn_inputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseq_len\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0monehot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m         \u001b[0mrnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_train\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m         \u001b[0mget_rnn_outputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseq_len\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrnn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseq_prob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-10-e75e396a22bc>\u001b[0m in \u001b[0;36mset_rnn_inputs\u001b[1;34m(seq_len, idx, onehot, X, param_dict)\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnext_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mset_onehot_input\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0monehot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m         \u001b[0mparam_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdata_key\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0monehot\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m         \u001b[0mparam_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlabel_key\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0midx\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/bing/github/mxnet/python/mxnet/ndarray.py\u001b[0m in \u001b[0;36m__setitem__\u001b[1;34m(self, in_slice, value)\u001b[0m\n\u001b[0;32m    191\u001b[0m             \u001b[0mNDArray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgeneric\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 193\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sync_copyfrom\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    194\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'type %s not supported'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/bing/github/mxnet/python/mxnet/ndarray.py\u001b[0m in \u001b[0;36m_sync_copyfrom\u001b[1;34m(self, source_array)\u001b[0m\n\u001b[0;32m    224\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m             \u001b[0msource_array\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_as\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmx_float_p\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 226\u001b[1;33m             ctypes.c_size_t(source_array.size)))\n\u001b[0m\u001b[0;32m    227\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    228\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_slice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def set_rnn_inputs(seq_len, idx, onehot, X, param_dict):\n",
    "    for j in range(seq_len):\n",
    "        data_key = \"t_%d_data\" % j\n",
    "        label_key = \"t_%d_label\" % j\n",
    "        next_idx = (idx + 1) % X.shape[0]\n",
    "        x = X[idx, :]\n",
    "        y = X[next_idx, :]\n",
    "        set_onehot_input(onehot, x)\n",
    "        param_dict[data_key][:] = onehot\n",
    "        param_dict[label_key][:] = y\n",
    "        idx += 1\n",
    "\n",
    "def get_rnn_outputs(seq_len, rnn, seq_prob):\n",
    "    for j in range(seq_len):\n",
    "        seq_prob[j][:] = rnn.outputs[j]\n",
    "\n",
    "def get_nll(seq_len, idx, X, seq_prob):\n",
    "    nll = 0.\n",
    "    for j in range(seq_len):\n",
    "        next_idx = (idx + 1) % X.shape[0]\n",
    "        y = X[next_idx, :]\n",
    "        nll += Logloss(y, seq_prob[j].asnumpy())\n",
    "    return nll\n",
    "    \n",
    "\n",
    "for i in range(num_round):\n",
    "    nbatch = 0.\n",
    "    nll = 0.\n",
    "    # reset states\n",
    "    for init_c, init_h in init_states:\n",
    "        init_c[:] = 0.\n",
    "        init_h[:] = 0.\n",
    "    tic = time.time()\n",
    "    # train\n",
    "    while nbatch < X_train_batch.shape[0]:\n",
    "        set_rnn_inputs(seq_len, nbatch, onehot, X_train_batch, param_dict)\n",
    "        rnn.forward(is_train=True)\n",
    "        get_rnn_outputs(seq_len, rnn, seq_prob)\n",
    "        rnn.backward()\n",
    "        for ind, weight, grad in param_array:\n",
    "            optimizer.update(ind, weight, grad, None)\n",
    "        for j in range(num_layer):\n",
    "            init_states[j][0][:] = last_states[j][0]\n",
    "            init_states[j][1][:] = last_states[j][1]\n",
    "        nll += get_nll(seq_len, nbatch, X_train_batch, seq_prob)\n",
    "        nbatch += seq_len\n",
    "        if nbatch % 1000 == 0:\n",
    "            print(\"Epoch [%d], Batch [%d]: NLL=%.3f, Prep=%.3f\" % (i, nbatch, nll / nbatch, np.exp(nll / nbatch)))\n",
    "    toc = time.time()\n",
    "    print(\"Epoch [%d] Train: Time: %.3f sec, NLL=%.3f, Prep=%.3f\" % (i, toc - tic, nll / nbatch, np.exp(nll / nbatch)))\n",
    "    nbatch = 0\n",
    "    nll = 0.\n",
    "    for init_c, init_h in init_states:\n",
    "        init_c[:] = 0.\n",
    "        init_h[:] = 0.\n",
    "    while nbatch < X_val_batch.shape[0]:\n",
    "        set_rnn_inputs(seq_len, nbatch, onehot, X_val_batch, param_dict)\n",
    "        rnn.forward(is_train=False)\n",
    "        get_rnn_outputs(seq_len, rnn, seq_prob)\n",
    "        nll += get_nll(seq_len, nbatch, X_val_batch, seq_prob)\n",
    "        nbatch += seq_len\n",
    "    print(\"Epoch [%d] Val: NLL=%.3f, Prep=%.3f\" % (i, nll / nbatch, np.exp(nll / nbatch)))\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<mxnet.symbol.Symbol at 0x7f8c5f3df080>"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
