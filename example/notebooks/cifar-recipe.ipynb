{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIFAR-10 Recipe\n",
    "In this notebook, we will show how to train a state-of-art CIFAR-10 network with MXNet and extract feature from the network.\n",
    "This example wiil cover\n",
    "\n",
    "- Network/Data definition \n",
    "- Model saving and loading\n",
    "- Learning rate schedule\n",
    "- Extracting feature from network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import mxnet as mx\n",
    "import logging\n",
    "\n",
    "# setup logging\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "console = logging.StreamHandler()\n",
    "console.setLevel(logging.DEBUG)\n",
    "logging.getLogger('').addHandler(console)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's make some helper function to let us build a simplified Inception Network. More details about how to composite symbol into component can be found at [component demo](composite_symbol.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Basic Conv + BN + ReLU factory\n",
    "def ConvFactory(data, num_filter, kernel, stride=(1,1), pad=(0, 0), act_type=\"relu\"):\n",
    "    conv = mx.symbol.Convolution(data=data, num_filter=num_filter, kernel=kernel, stride=stride, pad=pad)\n",
    "    bn = mx.symbol.BatchNorm(data=conv)\n",
    "    act = mx.symbol.Activation(data = bn, act_type=act_type)\n",
    "    return act"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A Simple Downsampling Factory\n",
    "def DownsampleFactory(data, ch_3x3):\n",
    "    # conv 3x3\n",
    "    conv = ConvFactory(data=data, kernel=(3, 3), stride=(2, 2), num_filter=ch_3x3, pad=(1, 1))\n",
    "    # pool\n",
    "    pool = mx.symbol.Pooling(data=data, kernel=(3, 3), stride=(2, 2), pool_type='max')\n",
    "    # concat\n",
    "    concat = mx.symbol.Concat(*[conv, pool])\n",
    "    return concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A Simple module\n",
    "def SimpleFactory(data, ch_1x1, ch_3x3):\n",
    "    # 1x1\n",
    "    conv1x1 = ConvFactory(data=data, kernel=(1, 1), pad=(0, 0), num_filter=ch_1x1)\n",
    "    # 3x3\n",
    "    conv3x3 = ConvFactory(data=data, kernel=(3, 3), pad=(1, 1), num_filter=ch_3x3)\n",
    "    #concat\n",
    "    concat = mx.symbol.Concat(*[conv1x1, conv3x3])\n",
    "    return concat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can build a network with these component factories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = mx.symbol.Variable(name=\"data\")\n",
    "conv1 = ConvFactory(data=data, kernel=(3,3), pad=(1,1), num_filter=96, act_type=\"relu\")\n",
    "in3a = SimpleFactory(conv1, 32, 32)\n",
    "in3b = SimpleFactory(in3a, 32, 48)\n",
    "in3c = DownsampleFactory(in3b, 80)\n",
    "in4a = SimpleFactory(in3c, 112, 48)\n",
    "in4b = SimpleFactory(in4a, 96, 64)\n",
    "in4c = SimpleFactory(in4b, 80, 80)\n",
    "in4d = SimpleFactory(in4c, 48, 96)\n",
    "in4e = DownsampleFactory(in4d, 96)\n",
    "in5a = SimpleFactory(in4e, 176, 160)\n",
    "in5b = SimpleFactory(in5a, 176, 160)\n",
    "pool = mx.symbol.Pooling(data=in5b, pool_type=\"avg\", kernel=(7,7))\n",
    "flatten = mx.symbol.Flatten(data=pool)\n",
    "fc = mx.symbol.FullyConnected(data=flatten, num_hidden=10)\n",
    "loss = mx.symbol.Softmax(data=fc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# If you'd like to see the network structure, run the plot_network function\n",
    "# mx.viz.plot_network(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Find duplicated argument name \"weight\", please make the weight name non-duplicated(using name arguments), arguments are ['data', 'weight', 'bias', 'gamma', 'beta', 'weight', 'bias', 'gamma', 'beta', 'weight', 'bias', 'gamma', 'beta', 'weight', 'bias', 'gamma', 'beta', 'weight', 'bias', 'gamma', 'beta', 'weight', 'bias', 'gamma', 'beta', 'weight', 'bias', 'gamma', 'beta', 'weight', 'bias', 'gamma', 'beta', 'weight', 'bias', 'gamma', 'beta', 'weight', 'bias', 'gamma', 'beta', 'weight', 'bias', 'gamma', 'beta', 'weight', 'bias', 'gamma', 'beta', 'weight', 'bias', 'gamma', 'beta', 'weight', 'bias', 'gamma', 'beta', 'weight', 'bias', 'gamma', 'beta', 'weight', 'bias', 'gamma', 'beta', 'weight', 'bias', 'gamma', 'beta', 'weight', 'bias', 'gamma', 'beta', 'weight', 'bias', 'gamma', 'beta', 'weight', 'bias', 'label']",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-b112c5ebf964>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# For demo purpose, this model only train 1 round\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m model = mx.model.FeedForward(ctx=mx.gpu(), symbol=loss, num_round = 1,\n\u001b[1;32m----> 4\u001b[1;33m                               learning_rate=0.05, momentum=0.9, wd=0.00001)\n\u001b[0m",
      "\u001b[1;32m/home/bing/wtf/mxnet/python/mxnet/model.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, symbol, ctx, num_round, optimizer, initializer, arg_params, aux_params, **kwargs)\u001b[0m\n\u001b[0;32m    418\u001b[0m                  **kwargs):\n\u001b[0;32m    419\u001b[0m         \u001b[1;31m# check if symbol contain duplicated names.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 420\u001b[1;33m         \u001b[0m_check_arguments\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msymbol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    421\u001b[0m         \u001b[1;31m# basic configuration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    422\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msymbol\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msymbol\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/bing/wtf/mxnet/python/mxnet/model.py\u001b[0m in \u001b[0;36m_check_arguments\u001b[1;34m(symbol)\u001b[0m\n\u001b[0;32m     61\u001b[0m             raise ValueError(('Find duplicated argument name \\\"%s\\\", ' +\n\u001b[0;32m     62\u001b[0m                               \u001b[1;34m'please make the weight name non-duplicated(using name arguments), '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                               'arguments are %s') % (name, str(arg_names)))\n\u001b[0m\u001b[0;32m     64\u001b[0m         \u001b[0marg_set\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Find duplicated argument name \"weight\", please make the weight name non-duplicated(using name arguments), arguments are ['data', 'weight', 'bias', 'gamma', 'beta', 'weight', 'bias', 'gamma', 'beta', 'weight', 'bias', 'gamma', 'beta', 'weight', 'bias', 'gamma', 'beta', 'weight', 'bias', 'gamma', 'beta', 'weight', 'bias', 'gamma', 'beta', 'weight', 'bias', 'gamma', 'beta', 'weight', 'bias', 'gamma', 'beta', 'weight', 'bias', 'gamma', 'beta', 'weight', 'bias', 'gamma', 'beta', 'weight', 'bias', 'gamma', 'beta', 'weight', 'bias', 'gamma', 'beta', 'weight', 'bias', 'gamma', 'beta', 'weight', 'bias', 'gamma', 'beta', 'weight', 'bias', 'gamma', 'beta', 'weight', 'bias', 'gamma', 'beta', 'weight', 'bias', 'gamma', 'beta', 'weight', 'bias', 'gamma', 'beta', 'weight', 'bias', 'gamma', 'beta', 'weight', 'bias', 'label']"
     ]
    }
   ],
   "source": [
    "# We will make model with current current symbol\n",
    "# For demo purpose, this model only train 1 round\n",
    "model = mx.model.FeedForward(ctx=mx.gpu(), symbol=loss, num_round = 1,\n",
    "                             learning_rate=0.05, momentum=0.9, wd=0.00001)\n",
    "# To make automatic model saving after each round, we can add check_point callback\n",
    "# model_prefix = \"cifar\"\n",
    "# model = mx.model.FeedForward(ctx=mx.gpu(), symbol=loss, num_round = 1,\n",
    "#                              learning_rate=0.05, momentum=0.9, wd=0.00001,\n",
    "#                              iter_end_callback=mx.model.do_checkpoint(model_prefix))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next step is declaring data iterator. The original CIFAR-10 data is 3x32x32 in binary format, we provides RecordIO format, so we can use Image RecordIO format. For more infomation about Image RecordIO Iterator, check [document](https://mxnet.readthedocs.org/en/latest/python/io.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use utility function in test to download the data\n",
    "import sys\n",
    "sys.path.append(\"../../tests/python/common\")\n",
    "import get_data\n",
    "get_data.GetCifar10()\n",
    "# After we get the data, we can declare our data iterator\n",
    "# The iterator will automatically create mean image file if it doesn't exist\n",
    "batch_size = 128\n",
    "# Train iterator make batch of 128 image, and random crop each image into 3x28x28 from original 3x32x32\n",
    "train_dataiter = mx.io.ImageRecordIter(\n",
    "        shuffle=True,\n",
    "        path_imgrec=\"data/cifar/train.rec\",\n",
    "        mean_img=\"data/cifar/cifar_mean.bin\",\n",
    "        rand_crop=True,\n",
    "        rand_mirror=True,\n",
    "        data_shape=(3,28,28),\n",
    "        batch_size=batch_size,\n",
    "        preprocess_threads=1)\n",
    "# test iterator make batch of 128 image, and center crop each image into 3x28x28 from original 3x32x32\n",
    "test_dataiter = mx.io.ImageRecordIter(\n",
    "        path_imgrec=\"data/cifar/test.rec\",\n",
    "        mean_img=\"data/cifar/cifar_mean.bin\",\n",
    "        rand_crop=False,\n",
    "        rand_mirror=False,\n",
    "        data_shape=(3,28,28),\n",
    "        batch_size=batch_size,\n",
    "        preprocess_threads=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
